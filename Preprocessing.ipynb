{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de4ae6c5d927387",
   "metadata": {},
   "source": [
    "Данный ноутбук содержит в себе части кода, которые нужны для предобработки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc8965e0be343",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168b499d0ecb27c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:11.996861Z",
     "start_time": "2024-08-28T12:33:11.802253Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import imageio\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8cd4bbfd7ab6a",
   "metadata": {},
   "source": [
    "# Предобработки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6137ec85c8cb",
   "metadata": {},
   "source": [
    "### 1) Создание нового csv файла, в котором Mass и Nodule объединены в один класс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d84951-bc73-4aba-8717-cf988a44d1cd",
   "metadata": {},
   "source": [
    "Файл Data_Entry_2017_v2020.csv вы можете скачать по ссылке: https://nihcc.app.box.com/v/ChestXray-NIHCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9ee49735a395d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:16.185325Z",
     "start_time": "2024-08-28T12:33:16.182432Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data Kaggle/Data_Entry_2017_v2020.csv')\n",
    "\n",
    "def replace_labels(label):\n",
    "    if 'Mass' in label and 'Nodule' in label:\n",
    "        return label.replace('Mass', '').replace('Nodule', 'Nodule/Mass').replace('||', '|').strip('|')\n",
    "    elif 'Mass' in label:\n",
    "        return label.replace('Mass', 'Nodule/Mass')\n",
    "    elif 'Nodule' in label:\n",
    "        return label.replace('Nodule', 'Nodule/Mass')\n",
    "    else:\n",
    "        return label\n",
    "\n",
    "df['Finding Labels'] = df['Finding Labels'].apply(replace_labels)\n",
    "df.to_csv('Data Kaggle/Data_Entry_2017_v2020_edit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b83763e730cc2",
   "metadata": {},
   "source": [
    "### 2) Расчёт размеров Bbox для патологий Nodule и Mass в сантиметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f6e4ef97dac3ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:21.304902Z",
     "start_time": "2024-08-28T12:33:21.302610Z"
    }
   },
   "outputs": [],
   "source": [
    "data_entry = pd.read_csv('Data Kaggle/Data_Entry_2017_v2020.csv')\n",
    "bbox_list = pd.read_csv('Data Kaggle/BBox_List_2017.csv')\n",
    "\n",
    "filtered_bbox = bbox_list[bbox_list['Finding Label'].isin(['Nodule', 'Mass'])]\n",
    "\n",
    "merged_data = pd.merge(filtered_bbox, data_entry, on='Image Index')\n",
    "\n",
    "merged_data['w_cm'] = merged_data['w'] * merged_data['OriginalImagePixelSpacing[x']\n",
    "merged_data['h_cm'] = merged_data['h]'] * merged_data['y]']\n",
    "\n",
    "final_data = merged_data[['Image Index', 'Finding Label', 'w_cm', 'h_cm']]\n",
    "\n",
    "final_data.to_csv('Data Kaggle/BBox_size_cm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ba4993dd6878c",
   "metadata": {},
   "source": [
    "### 3) Преобразование данных NODE21 из .mha в .png для изображений с Nodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343626d800266dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:26.001464Z",
     "start_time": "2024-08-28T12:33:25.997003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Путь к директории с исходными изображениями\n",
    "source_dir = 'NODE21/dataset_node21/cxr_images/original_data/images'\n",
    "\n",
    "# Путь к директории для сохранения обработанных изображений\n",
    "target_dir = 'NODE21/dataset_node21/cxr_images/original_data/png_Nodule'\n",
    "\n",
    "# Путь к CSV-файлу с соответствием имен\n",
    "csv_file = 'NODE21/dataset_node21/cxr_images/original_data/filenames_orig_and_new.csv'\n",
    "\n",
    "# Словарь для сопоставления node21_img_id с original_image_name\n",
    "id_name_mapping = {}\n",
    "\n",
    "# Чтение данных из CSV-файла и заполнение словаря\n",
    "with open(csv_file, mode='r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for row in reader:\n",
    "        id_name_mapping[row['node21_img_id']] = row['original_image_name']\n",
    "\n",
    "# Проверка наличия директории для сохранения изображений\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "# Обход всех файлов в исходной директории\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith('.mha'):\n",
    "        # Получение original_image_name из словаря\n",
    "        original_name = id_name_mapping.get(filename.replace('.mha', ''), None)\n",
    "        if original_name:\n",
    "            # Загрузка изображения\n",
    "            image_data, image_header = load(os.path.join(source_dir, filename))\n",
    "\n",
    "            # Поворот изображения на 90 градусов вправо\n",
    "            image_data_rotated = np.rot90(image_data, -1)\n",
    "\n",
    "            # Нормализация изображения для удаления прозрачности\n",
    "            image_data_normalized = ((image_data_rotated - np.min(image_data_rotated)) * (255 / (np.max(image_data_rotated) - np.min(image_data_rotated)))).astype(np.uint8)\n",
    "\n",
    "            # Сохранение обработанного изображения в формате PNG с original_image_name\n",
    "            imageio.imwrite(os.path.join(target_dir, original_name + '.png'), image_data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe502e6c2b131e8",
   "metadata": {},
   "source": [
    "### 4) Преобразование данных NODE21 из .mha в .png для изображений без Nodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbc6102688e715d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:32.132437Z",
     "start_time": "2024-08-28T12:33:32.130156Z"
    }
   },
   "outputs": [],
   "source": [
    "# Путь к директории с исходными изображениями\n",
    "source_dir = 'NODE21/dataset_node21/cxr_images/original_data/images'\n",
    "\n",
    "# Путь к директории для сохранения обработанных изображений\n",
    "target_dir = 'NODE21/dataset_node21/cxr_images/original_data/png_clean'\n",
    "\n",
    "# Проверка наличия директории для сохранения изображений\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "# Обход всех файлов в исходной директории\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.startswith('c') and filename.endswith('.mha'):\n",
    "        # Загрузка изображения\n",
    "        image_data, image_header = load(os.path.join(source_dir, filename))\n",
    "\n",
    "        # Поворот изображения на 90 градусов вправо\n",
    "        image_data_rotated = np.rot90(image_data, -1)\n",
    "\n",
    "        # Нормализация изображения для удаления прозрачности\n",
    "        image_data_normalized = ((image_data_rotated - np.min(image_data_rotated)) * (255 / (np.max(image_data_rotated) - np.min(image_data_rotated)))).astype(np.uint8)\n",
    "\n",
    "        # Сохранение обработанного изображения в формате PNG\n",
    "        imageio.imwrite(os.path.join(target_dir, filename.replace('.mha', '.png')), image_data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503f85eb4cf2421",
   "metadata": {},
   "source": [
    "###  5) Копировние данных XRay Chest Nodule, где возраст от 18 лет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84b39f695b41fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:35.926639Z",
     "start_time": "2024-08-28T12:33:35.923993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Загрузка данных из CSV-файла\n",
    "data = pd.read_csv('Data Kaggle/Data_Entry_2017_v2020_edit.csv')\n",
    "\n",
    "# Путь к папке с исходными изображениями\n",
    "source_folder = 'More Bbox Nodule/From kaggle/'\n",
    "\n",
    "# Путь к папке назначения\n",
    "destination_folder = 'More Bbox Nodule/vs/'\n",
    "\n",
    "# Создание папки назначения, если она не существует\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# Копирование изображений\n",
    "for index, row in data.iterrows():\n",
    "    # Проверка возраста пациента\n",
    "    if row['Patient Age'] >= 18:\n",
    "        # Полный путь к исходному изображению\n",
    "        source_image = os.path.join(source_folder, row['Image Index'])\n",
    "        # Полный путь к изображению в папке назначения\n",
    "        destination_image = os.path.join(destination_folder, row['Image Index'])\n",
    "\n",
    "        # Копирование изображения, если оно существует\n",
    "        if os.path.isfile(source_image):\n",
    "            shutil.copy2(source_image, destination_image)\n",
    "            print(f'Изображение {row[\"Image Index\"]} скопировано.')\n",
    "        else:\n",
    "            print(f'Изображение {row[\"Image Index\"]} не найдено в исходной папке.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067bcafa739fc55",
   "metadata": {},
   "source": [
    "### 6) Копирование изображений из XRay Chest Nodule, которых нет в NODE21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5982c7b789ae76fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:40.844999Z",
     "start_time": "2024-08-28T12:33:40.842622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Путь к папке с исходными изображениями\n",
    "source_folder = 'More Bbox Nodule/vs/'\n",
    "\n",
    "# Путь к папке, где уже есть некоторые изображения\n",
    "existing_images_folder = 'NODE21/dataset_node21/cxr_images/original_data/png_Nodule/'\n",
    "\n",
    "# Путь к папке назначения\n",
    "destination_folder = 'More Bbox Nodule/merge/'\n",
    "\n",
    "# Создание папки назначения, если она не существует\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# Получение списка имен файлов в папке с существующими изображениями\n",
    "existing_images = set(os.listdir(existing_images_folder))\n",
    "\n",
    "# Копирование изображений\n",
    "for image_name in os.listdir(source_folder):\n",
    "    # Проверка, существует ли изображение в папке с существующими изображениями\n",
    "    if image_name not in existing_images:\n",
    "        # Полный путь к исходному изображению\n",
    "        source_image = os.path.join(source_folder, image_name)\n",
    "        # Полный путь к изображению в папке назначения\n",
    "        destination_image = os.path.join(destination_folder, image_name)\n",
    "\n",
    "        # Копирование изображения\n",
    "        shutil.copy2(source_image, destination_image)\n",
    "        print(f'Изображение {image_name} скопировано.')\n",
    "    else:\n",
    "        print(f'Изображение {image_name} уже существует в папке назначения.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812b720cffa607d",
   "metadata": {},
   "source": [
    "### 7) Предобработка масок для данных Шэньчжэнь и Монтгомери, чтобы сердце также попадало в сегментацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48be4e696c3811f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:13.398847Z",
     "start_time": "2024-08-28T12:34:13.396173Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_masks(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    mask_files = os.listdir(input_folder)\n",
    "\n",
    "    for filename in mask_files:\n",
    "        mask_path = os.path.join(input_folder, filename)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        original_mask = mask.copy()\n",
    "        no_white_col = find_no_white_col(mask)\n",
    "        red_row, right_col_with_white = find_right_col_with_white(mask, no_white_col)\n",
    "        bottom_row_with_white = find_bottom_row_with_white(mask, right_col_with_white)\n",
    "        modified_mask = fill_white_area(mask.copy(), right_col_with_white, bottom_row_with_white, red_row)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, modified_mask)\n",
    "\n",
    "    print(\"Обработка завершена.\")\n",
    "\n",
    "def find_no_white_col(mask):\n",
    "    center = mask.shape[1] // 2\n",
    "    no_white_col = 0\n",
    "    for i in range(mask.shape[1]):\n",
    "        if i % 2 == 0:\n",
    "            col = center + i // 2\n",
    "        else:\n",
    "            col = center - i // 2\n",
    "        if not np.any(mask[:, col] == 255):\n",
    "            no_white_col = col\n",
    "            break\n",
    "    return no_white_col\n",
    "\n",
    "def find_right_col_with_white(mask, start_col):\n",
    "    for col in range(start_col, mask.shape[1]):\n",
    "        if np.any(mask[:, col] == 255):\n",
    "            row = np.argmax(mask[:, col] == 255)\n",
    "            return (row, col)\n",
    "    return (-1, -1) \n",
    "\n",
    "def find_bottom_row_with_white(mask, start_col):\n",
    "    for row in range(mask.shape[0] - 1, -1, -1):\n",
    "        if np.any(mask[row, start_col:] == 255):\n",
    "            return row\n",
    "    return -1\n",
    "\n",
    "def fill_white_area(mask, blue_col, green_row, red_row):\n",
    "    if blue_col == -1 or green_row == -1:\n",
    "        return mask\n",
    "\n",
    "    for row in range(green_row, red_row, -1):\n",
    "        for col in range(blue_col, mask.shape[1]):\n",
    "            if mask[row, col] == 255:\n",
    "                break\n",
    "            mask[row, col] = 255\n",
    "    return mask\n",
    "\n",
    "process_masks('Data Segmentation Lung/data/Lung Segmentation/masks', 'Data Segmentation Lung/data/Lung Segmentation/masks_heart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a35d9d4997e28",
   "metadata": {},
   "source": [
    "### 8) Коверитруем из bmp в png и инвертируем изображение для данных JSRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cadfa8ffbaa2ede9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:17.519586Z",
     "start_time": "2024-08-28T12:34:17.517682Z"
    }
   },
   "outputs": [],
   "source": [
    "src_dir = 'JSRT/org'\n",
    "dst_dir = 'JSRT/org_png'\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('.bmp'):\n",
    "        img = Image.open(os.path.join(src_dir, filename))\n",
    "        img = ImageOps.invert(img)\n",
    "        img.save(os.path.join(dst_dir, filename[:-4] + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a213185584ad2e77",
   "metadata": {},
   "source": [
    "### 9) Для данных JSRT сделаем маски для сегментации лёгких и сердца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cd83183e897ecb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:20.658822Z",
     "start_time": "2024-08-28T12:34:20.655407Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('JSRT/label_cut', exist_ok=True)\n",
    "files = os.listdir('JSRT/label')\n",
    "\n",
    "for file in files:\n",
    "    mask = cv2.imread(f'JSRT/label/{file}', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    heart_mask = np.copy(mask)\n",
    "    heart_mask[(heart_mask == 85)] = 255\n",
    "    heart_mask[heart_mask != 255] = 0\n",
    "\n",
    "    center = mask.shape[1]//2\n",
    "    no_white_col = 0\n",
    "\n",
    "    for i in range(mask.shape[1]):\n",
    "        if i % 2 == 0:\n",
    "            col = center + i // 2\n",
    "        else:\n",
    "            col = center - i // 2\n",
    "        if not np.any(mask[:, col] == 255):\n",
    "            no_white_col = col\n",
    "            break\n",
    "\n",
    "    left_most = 0\n",
    "    right_most = 0\n",
    "\n",
    "    for i in range(no_white_col, -1, -1):\n",
    "        if np.any(mask[:, i] == 255):\n",
    "            left_most = i + 1  \n",
    "            break\n",
    "\n",
    "    for i in range(no_white_col, mask.shape[1]):\n",
    "        if np.any(mask[:, i] == 255):\n",
    "            right_most = i - 1  \n",
    "            break\n",
    "\n",
    "    heart_mask[:, left_most:right_most] = 0\n",
    "\n",
    "    cv2.imwrite(f'JSRT/label_cut/{file}', heart_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26eff4a9ee3916",
   "metadata": {},
   "source": [
    "### 10) Создание датасета для данных RSNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78c0d9013bd865a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:25.244590Z",
     "start_time": "2024-08-28T12:34:25.242684Z"
    }
   },
   "outputs": [],
   "source": [
    "rsna_df = pd.read_csv('Data rsna/lung-segmentation/train.csv')\n",
    "\n",
    "def add_path(image_name):\n",
    "    return 'Data rsna/lung-segmentation/images/' + image_name.split('.')[0] + '/image.png'\n",
    "\n",
    "\n",
    "def add_path_to_label(label_name):\n",
    "    return 'Data rsna/lung-segmentation/masks/' + label_name\n",
    "\n",
    "rsna_df['label'] = rsna_df['label'].apply(add_path_to_label)\n",
    "rsna_df['image'] = rsna_df['image'].apply(add_path)\n",
    "\n",
    "rsna_df.to_csv('Data rsna/lung-segmentation/updated_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef014e674e078b",
   "metadata": {},
   "source": [
    "### 11) Сохранение данных из train и test в один файл для XRay Chest Nodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1532fc5f4e46d141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:29.068801Z",
     "start_time": "2024-08-28T12:34:29.066899Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/train.csv')\n",
    "test = pd.read_csv('More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/test.csv')\n",
    "\n",
    "combined = pd.concat([train, test])\n",
    "\n",
    "combined.to_csv('More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bb64ee2916adb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:32.390404Z",
     "start_time": "2024-08-28T12:34:32.388402Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/combined.csv')\n",
    "data['filename'] = data['filename'].apply(lambda x: \"_\".join(x.split(\"_\")[:2]) + \".png\")\n",
    "data.to_csv('More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea1115588277741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:35.341483Z",
     "start_time": "2024-08-28T12:34:35.338456Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = 'More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/combined.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['width'] = df['xmax'] - df['xmin']\n",
    "df['height'] = df['ymax'] - df['ymin']\n",
    "\n",
    "new_df = pd.DataFrame({\n",
    "    'height': df['height'],\n",
    "    'img_name': df['filename'],\n",
    "    'label': 1,\n",
    "    'width': df['width'],\n",
    "    'x': df['xmin'],\n",
    "    'y': df['ymin']\n",
    "})\n",
    "\n",
    "output_file_path = 'More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/transformed_combined.csv'\n",
    "new_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3792f34878886",
   "metadata": {},
   "source": [
    "### 12) Сохранение изображений в формате .png для XRay Chest Nodule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d6db4-4bba-47e9-b4f6-0714cb4e627b",
   "metadata": {},
   "source": [
    "train и test это файлы _annotation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e29c4dc0ba60c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:38.458892Z",
     "start_time": "2024-08-28T12:34:38.456874Z"
    }
   },
   "outputs": [],
   "source": [
    "src_dir = \"More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/train/\"\n",
    "dst_dir = \"More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/png/\"\n",
    "\n",
    "if not os.path.exists(dst_dir):\n",
    "    os.makedirs(dst_dir)\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img = Image.open(os.path.join(src_dir, filename))\n",
    "        base_filename = \"_\".join(filename.split(\"_\")[:2])\n",
    "        img.save(os.path.join(dst_dir, base_filename + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e786061bcada5ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:41.431276Z",
     "start_time": "2024-08-28T12:34:41.428920Z"
    }
   },
   "outputs": [],
   "source": [
    "src_dir = \"More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/test/\"\n",
    "dst_dir = \"More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/png/\"\n",
    "\n",
    "if not os.path.exists(dst_dir):\n",
    "    os.makedirs(dst_dir)\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img = Image.open(os.path.join(src_dir, filename))\n",
    "        base_filename = \"_\".join(filename.split(\"_\")[:2])\n",
    "        img.save(os.path.join(dst_dir, base_filename + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670d43b275f00dc",
   "metadata": {},
   "source": [
    "### 13) Сохранить бинарные маски Bbox для XRay Chest Nodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d842e1b72d1e423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:44.944209Z",
     "start_time": "2024-08-28T12:34:44.941375Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/combined.csv')\n",
    "\n",
    "mask_dir = 'More Bbox Nodule/CXR.v1-chestx-ray_zhangjin_kaggle.tensorflow/png_mask/'\n",
    "if not os.path.exists(mask_dir):\n",
    "    os.makedirs(mask_dir)\n",
    "\n",
    "grouped = data.groupby('filename')\n",
    "\n",
    "for filename, group in grouped:\n",
    "    mask = np.zeros((group['height'].iloc[0], group['width'].iloc[0]), dtype=np.uint8)\n",
    "\n",
    "    for index, row in group.iterrows():\n",
    "        mask[row['ymin']:row['ymax'], row['xmin']:row['xmax']] = 255\n",
    "\n",
    "    mask_filename = os.path.join(mask_dir, filename)\n",
    "    cv2.imwrite(mask_filename, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e86e8abec4b30",
   "metadata": {},
   "source": [
    "### 14) Создание объединённого csv для NODE21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8dd87ebfad416a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:47.869815Z",
     "start_time": "2024-08-28T12:34:47.866770Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('NODE21/dataset_node21/cxr_images/original_data/metadata.csv')\n",
    "filenames_df = pd.read_csv('NODE21/dataset_node21/cxr_images/original_data/filenames_orig_and_new.csv')\n",
    "\n",
    "if 'Unnamed: 0' in metadata_df.columns:\n",
    "    metadata_df = metadata_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "mapping_dict = dict(zip(filenames_df['node21_img_id'], filenames_df['original_image_name']))\n",
    "\n",
    "def update_img_name(img_name):\n",
    "    if img_name.startswith('n') and img_name[:-4] in mapping_dict:\n",
    "        return mapping_dict[img_name[:-4]] + '.png'\n",
    "    elif img_name.startswith('c'):\n",
    "        return img_name[:-4] + '.png'\n",
    "    else:\n",
    "        return img_name\n",
    "\n",
    "metadata_df['img_name'] = metadata_df['img_name'].apply(update_img_name)\n",
    "metadata_df.to_csv('NODE21/dataset_node21/cxr_images/original_data/updated_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd8eb38bec0fcf",
   "metadata": {},
   "source": [
    "### 15) Сохранить бинарные маски Bbox для NODE21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b58a2f2a526632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T12:34:51.166702Z",
     "start_time": "2024-08-28T12:34:51.164176Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_file = 'NODE21/dataset_node21/cxr_images/original_data/updated_metadata.csv'\n",
    "output_folder = 'NODE21/dataset_node21/cxr_images/original_data/png_mask/'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(metadata_file)\n",
    "image_groups = df.groupby('img_name')\n",
    "\n",
    "for img_name, group in image_groups:\n",
    "    # Пропустить изображения, имена которых начинаются с 'c'\n",
    "    if img_name.startswith('c'):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join('NODE21/dataset_node21/cxr_images/original_data/png_Nodule/', img_name)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Файл не найден: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    # Создание пустой маски\n",
    "    mask = Image.new('L', (image_width, image_height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    # Нарисовать прямоугольники для каждого bbox на маске\n",
    "    for index, row in group.iterrows():\n",
    "        x, y, width, height = row['x'], row['y'], row['width'], row['height']\n",
    "        draw.rectangle([x, y, x + width, y + height], fill=255)\n",
    "\n",
    "    # Отзеркаливание маски по оси y\n",
    "    mask_np = np.array(mask)\n",
    "    mirrored_mask_np = np.flip(mask_np, axis=1)\n",
    "    mirrored_mask = Image.fromarray(mirrored_mask_np)\n",
    "\n",
    "    # Сохранение отзеркаленной маски\n",
    "    mask_filename = os.path.join(output_folder, os.path.splitext(img_name)[0] + '.png')\n",
    "    mirrored_mask.save(mask_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
